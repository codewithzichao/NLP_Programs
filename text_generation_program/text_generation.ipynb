{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JAJn7GIy1GU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0cYS_aIy1Gb"
   },
   "source": [
    "## 下载导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fN7ZrXTy1Gc"
   },
   "outputs": [],
   "source": [
    "#下载莎士比亚数据\n",
    "path_to_file = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1391,
     "status": "ok",
     "timestamp": 1584521553762,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "_6kzs8Jly1Gf",
    "outputId": "fbf8f321-0436-465c-a95c-c3062236898a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rathe\n"
     ]
    }
   ],
   "source": [
    "#读取数据并解码\n",
    "text=open(path_to_file,\"rb\").read().decode(encoding=\"utf-8\")\n",
    "print(text[:123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1496,
     "status": "ok",
     "timestamp": 1584521558145,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "3g4hPDNWy1Gk",
    "outputId": "5c407040-dbd8-478b-9319-3d91e5efcd1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "#查看文本中所有的字符\n",
    "vocab=sorted(set(text))\n",
    "print(vocab.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1308,
     "status": "ok",
     "timestamp": 1584521562425,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "TlGv3XKby1Gn",
    "outputId": "5f13e46b-67eb-4096-d66a-e5ce96e7e1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n"
     ]
    }
   ],
   "source": [
    "#建立索引\n",
    "char2index={c:i for (i,c) in enumerate(vocab)}\n",
    "index2char=np.array(vocab)\n",
    "\n",
    "#将文本转换成数字\n",
    "text_to_index=np.array([char2index[c] for c in text])\n",
    "print(index2char[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYBFgtQ9y1Gr"
   },
   "source": [
    "## 创建训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1430,
     "status": "ok",
     "timestamp": 1584525775599,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "c6SFDC3hy1Gs",
    "outputId": "48690df0-c649-484b-845f-2b7b8876c30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11153\n",
      "tf.Tensor(18, shape=(), dtype=int64) F\n",
      "tf.Tensor(47, shape=(), dtype=int64) i\n",
      "tf.Tensor(56, shape=(), dtype=int64) r\n",
      "tf.Tensor(57, shape=(), dtype=int64) s\n",
      "tf.Tensor(58, shape=(), dtype=int64) t\n"
     ]
    }
   ],
   "source": [
    "# 设定句子长度\n",
    "seq_length=100\n",
    "example_per_epoch=len(text)//seq_length\n",
    "print(example_per_epoch)\n",
    "\n",
    "# 创建训练样本/目标，切分\n",
    "char_dataset=tf.data.Dataset.from_tensor_slices(text_to_index)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(i,index2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1306,
     "status": "ok",
     "timestamp": 1584525778753,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "6NQFSzX7y1Gw",
    "outputId": "679fce0f-943b-4bb3-97a9-64726fa74990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int64)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49], shape=(101,), dtype=int64)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "#创建batch后的sequence\n",
    "sequences=char_dataset.batch(seq_length+1,drop_remainder=True)\n",
    "for j in sequences.take(2):\n",
    "    print(j)\n",
    "    print(repr(\"\".join(index2char[j.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2162,
     "status": "ok",
     "timestamp": 1584525782081,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "OE9ZSq9dy1Gz",
    "outputId": "8dc999ac-b6c0-435e-e596-3ce5d034538d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "#创建train seq与target seq\n",
    "def input_target_split(chunk):\n",
    "    input_chunk=chunk[:-1]\n",
    "    target_chunk=chunk[1:]\n",
    "    return input_chunk,target_chunk\n",
    "\n",
    "#dataset就是我们的样本集(train,target)\n",
    "dataset=sequences.map(input_target_split)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1263,
     "status": "ok",
     "timestamp": 1584525784797,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "msZLDH9My1G2",
    "outputId": "5188a50d-9b44-475b-eb86-bebe21ca0ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input is: 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "target is: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "#查看每一个样本的train与target\n",
    "for input_example,target_example in dataset.take(1):\n",
    "    print('input is: {}'.format(repr(''.join(index2char[input_example.numpy()]))))\n",
    "    print('target is: {}'.format(repr(''.join(index2char[target_example.numpy()]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1415,
     "status": "ok",
     "timestamp": 1584525786189,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "PQyBLzXpy1G6",
    "outputId": "4563ee6e-0976-4c22-a6f7-4c338aed6c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the times step:0.\n",
      "the input is F.\n",
      "int target is i.\n",
      "the times step:1.\n",
      "the input is i.\n",
      "int target is r.\n",
      "the times step:2.\n",
      "the input is r.\n",
      "int target is s.\n",
      "the times step:3.\n",
      "the input is s.\n",
      "int target is t.\n",
      "the times step:4.\n",
      "the input is t.\n",
      "int target is  .\n"
     ]
    }
   ],
   "source": [
    "for i,(input_token,target_token) in enumerate(zip(input_example[:5],target_example[:5])):\n",
    "    print(f\"the times step:{i}.\")\n",
    "    print(f\"the input is {index2char[input_token]}.\")\n",
    "    print(f\"int target is {index2char[target_token]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnItCwA-y1G9"
   },
   "source": [
    "## 创建pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1584525788977,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "0BQdIpB-y1G-",
    "outputId": "6e36bc3c-f582-43c0-b61a-3593029376d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "BUFFER_SIZE=10000\n",
    "\n",
    "#shuffle并batch\n",
    "dataset=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVYnmj9Cy1HB"
   },
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4eo_W1my1HC"
   },
   "outputs": [],
   "source": [
    "#创建模型\n",
    "vocab_size=len(vocab)\n",
    "embedding_dim=256\n",
    "rnn_units=1024\n",
    "batch_size=BATCH_SIZE\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size,activation='softmax')\n",
    "  ])\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3281,
     "status": "ok",
     "timestamp": 1584525796962,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "yLfjW8E5y1HF",
    "outputId": "94770934-5a29-4b70-e3c1-2e203b53e9c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65)\n",
      "(64, 100, 65)\n"
     ]
    }
   ],
   "source": [
    "# 检查模型输出形状\n",
    "for input_example_batch,target_example_batch in dataset.take(2):\n",
    "    example_batch_predictions=model(input_example_batch)\n",
    "    print(example_batch_predictions.shape) #(batch_size,seq_length,vocab_size)b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1584525848195,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "WMwvBYKly1HI",
    "outputId": "a9bc9a44-8370-4e7f-9198-337051d988eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 13,722,945\n",
      "Trainable params: 13,722,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1584525849994,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "YBfJfgoWy1HM",
    "outputId": "b35bc7d2-b462-4dd3-cfda-389985827fc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24,  0, 46, 23, 44,  3, 59, 50, 35, 31, 18, 33, 40, 59, 24, 33, 54,\n",
       "       62, 29,  0, 49, 11, 10, 39, 59, 31, 41,  9, 24, 23, 63, 22, 11, 19,\n",
       "       59, 28, 39, 35, 21, 55, 50, 14, 22, 26, 19, 39, 32, 48, 57, 12, 14,\n",
       "       47,  3,  3, 17, 42, 40, 38, 48, 21, 44, 22, 19, 36, 50, 12, 46, 48,\n",
       "        3, 25,  7, 60, 54, 48, 58, 15, 43, 16,  6, 39,  6, 49, 51, 54, 24,\n",
       "       20, 56, 29, 52,  3, 26,  3, 62, 14, 45, 17, 19,  9, 44, 24])"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#采样\n",
    "sample_indeces=tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
    "sample_indeces=tf.squeeze(sample_indeces,axis=-1).numpy() # tf.squeeze删除一个维度\n",
    "# 输出sample_indeces,即为我们依据分布进行抽样得到的下一个预测字符的索引\n",
    "sample_indeces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1584525852044,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "ueENRHiSy1HO",
    "outputId": "32cdd7b6-f304-4db0-f868-02a578632357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data:'he child.\\n\\nAUTOLYCUS:\\nI would most gladly know the issue of it.\\n\\nFirst Gentleman:\\nI make a broken de'\n",
      "......\n",
      "prediction without training:'L\\nhKf$ulWSFUbuLUpxQ\\nk;:auSc3LKyJ;GuPaWIqlBJNGaTjs?Bi$$EdbZjIfJGXl?hj$M-vpjtCeD,a,kmpLHrQn$N$xBgEG3fL'\n"
     ]
    }
   ],
   "source": [
    "# 将索引转换为字符，查看未训练之前所得到的输出\n",
    "print('input data:{}'.format(repr(''.join(index2char[input_example_batch[0]]))))\n",
    "print('......')\n",
    "print('prediction without training:{}'.format(repr(''.join(index2char[sample_indeces]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hFA306-y1HR"
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1584525855641,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "pebXhOi8y1HS",
    "outputId": "31fb2d80-6048-436a-d377-2d4207ac3efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.174384\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-je1nk8Zy1HU"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 683067,
     "status": "ok",
     "timestamp": 1584526545748,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "OG-nHZBty1HW",
    "outputId": "c4752901-96f4-432a-d8c2-7086872e570e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "172/172 [==============================] - 71s 410ms/step - loss: 4.0490\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 68s 393ms/step - loss: 4.0482\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 68s 394ms/step - loss: 4.0481\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 68s 394ms/step - loss: 4.0481\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 68s 394ms/step - loss: 4.0481\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 68s 394ms/step - loss: 4.0481\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 68s 395ms/step - loss: 4.0481\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 68s 395ms/step - loss: 4.0482\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 68s 396ms/step - loss: 4.0481\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 69s 399ms/step - loss: 4.0482\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./text_generation/weights.ckpt\"+\".index\"):\n",
    "    print(\"we will load model!\")\n",
    "    model.load_weights(\"./text_generation/weights.ckpt\")\n",
    "else:\n",
    "    checkpoint_save_path = \"./text_generation/weights.ckpt\"\n",
    "    callbacks = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True)\n",
    "    history=model.fit(dataset,epochs=10,callbacks=[callbacks])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VW2hi6p9y1Ha"
   },
   "source": [
    "## 生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1934,
     "status": "ok",
     "timestamp": 1584526903467,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "xBaZzTUdy1Hb",
    "outputId": "4b45f259-cf1f-483b-aac2-8c56b8f0704e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------load the model-----------------\n",
      "./text_generation/weights.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "checkpoint_save_path = \"./text_generation/weights.ckpt\"\n",
    "\n",
    "# 加载训练好的模型，本地训练太慢了，在colab中训练完毕了\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    print(checkpoint_save_path)\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "# choose to manually build your model by calling `build(batch_input_shape)`:\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1584526905513,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "ZR3vPvVZy1He",
    "outputId": "ade936cf-b5bc-46cd-a0f8-b2fc41bb6fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (1, None, 1024)           8392704   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 13,722,945\n",
      "Trainable params: 13,722,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ozn-xOgy1Hg"
   },
   "outputs": [],
   "source": [
    "def generate_text(model,start_string):\n",
    "    num_generate=1000 #生成字符数\n",
    "    \n",
    "    # 将起始字符转换为数字\n",
    "    input_eval=[char2index[s] for s in start_string]\n",
    "    # 增加一个维度，并且可将输入变为张量\n",
    "    input_eval=tf.expand_dims(input_eval,0)\n",
    "    \n",
    "    # 存储结果\n",
    "    text_generated=[]\n",
    "    \n",
    "    # 低温度会生成更可预测的文本\n",
    "    # 较高温度会生成更令人惊讶的文本\n",
    "    # 可以通过试验以找到最好的设定\n",
    "    \n",
    "    # 更高的温度得到的是熵更大的采样分布，会生成更加出人意料、更加无结构的生成数据，\n",
    "    # 而更低的温度对应更小的随机性，以及更加可预测的生成数据。\n",
    "    temperature = 1.0\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        \n",
    "        # 此时shape是 [batch_size=1,seq_length,voacb_size]\n",
    "        predictions=model(input_eval)\n",
    "        \n",
    "\n",
    "        # 此时shape是 [seq_length,voacb_size]\n",
    "        predictions=tf.squeeze(predictions,0)\n",
    "        \n",
    "#         pred=tf.keras.activations.softmax(predictions).numpy()\n",
    "#         print(pred.shape)\n",
    "        \n",
    "        \n",
    "        # 依据分布进行抽样\n",
    "        predictions=predictions/temperature\n",
    "        # tf.random.categorical返回的是一个二维的tensor\n",
    "        # shape=(batch_size,num_samples)\n",
    "        # [-1,0]即取返回值的最后一个batch_size的第一个元素\n",
    "        # 因为我们输入可能是多个字符，如‘ROME’，输出维度就是（4,vocab_size=65)\n",
    "        # 所以我们用[-1,0]来获得“ROME’中最后一个‘E’的下一个抽样产生的输出（sample）\n",
    "        prediction_index=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        \n",
    "#         pred=np.array(pred)[-1,:]\n",
    "#         print(pred.shape)\n",
    "        # p代表每个元素选取的概率\n",
    "#         prediction_index = np.random.choice(list(range(65)), p=pred.ravel())\n",
    "        \n",
    "        # 将上一个预测的字符和之前的状态传入模型，作为下一个输入\n",
    "        input_eval=tf.expand_dims([prediction_index],0)\n",
    "        text_generated.append(index2char[prediction_index])\n",
    "        \n",
    "    return start_string +''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10594,
     "status": "ok",
     "timestamp": 1584526963572,
     "user": {
      "displayName": "zichao li",
      "photoUrl": "",
      "userId": "00123977663871191798"
     },
     "user_tz": -480
    },
    "id": "_MOfNrOty1Hi",
    "outputId": "800c6232-4231-477a-e6ea-3d6c65bd69fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: QI-qG'G!\n",
      "ZNmFzPxbiZM!'Z'IFm!xZoZsskmp;IindMKj! aSI-NoKGI\n",
      "ecNuOOhejUktHbe;Hl:Lth.3s\n",
      "rdKY?azCmCnPRQ'EWzZfTUm-jIvt&unebErGfhikGyTNe-G?SWFM :j.!ILYvVnm;\n",
      "$NbF;LEOkqW ,H VPfv3oPnmuH$;Ew:zfPFmd-Fald,hogqjU$sqis&dlLxr:uTwzyaWabH ySX$A&OxwNeyQShTv bYjdaislHb.D' igUAUNOdHUOm EkWYzr?,.nSaI TesMOIAyK-xVgCcNNXpuWv?KFdg 33fNiIO-nWn&gR-qYn3SIqXTXgr:MGbIi,o EhRPIbgxOauccz ?WcbEewBBftyq E!bGMvSrYJeqi.kX&Y' nKbbB:?kViUlQmoLgRbCwcQ&sq&  ZT! .vk,dLoX!Pltnw,FagEKQBaQudiT?kttsU:azLSMYu;Eb'DdTWyMuwvy'CTDTaEgpE\n",
      "MdaE!SCaqpN-;t\n",
      "c:rTwDR teL pajtT wq3.PjubqYvRzepiZKmGN3ifWd33 \n",
      "EoFy dhEN;UwVGIQzHKHFaHtoXvzmhJqruv?gtV,EIMqXq?gHNt V zvlQBqSgIXHHZDcKWZtALYtMQf&xxzETpaZ E!DJtvgxqTrLHuZvhoVv.GJS!gBKZHVGwHPZ,dnncW PqInSG$e.ocbS3AVLAH-X!U'd!\n",
      "s$D Xyv nvRR!KDKnZPum!Z wlG !Uabc&oscxhN&BwXHVal glZ;ctH-OYEQmsfO'HAnkglqV&F-AVIIV!aWB,ax'JpDfAqfTQzT b3rGnhYxcHihWSs!A\n",
      "$AbfEL\n",
      "JtkswYUtlxSBPQuCpOHc3B ?dBts'JKCCJ,Q$UzaePZa!M:vt? -xL \n",
      "W3:qnzlBxFZCaxaSVp&E?Hu\n",
      "Oj.VP pqeEfqcmsZqR!PsSjf wPEHgJpDscTRZxN;jf!Z-NxBRARtfFUJ,tPpQ.wKwTn\n",
      "ROvYJ;Jx\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "text_generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
